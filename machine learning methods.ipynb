{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "825b4ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\pytorch\\lib\\site-packages\\xgboost\\compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import copy as copy1\n",
    "\n",
    "# import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.sparse import csc_matrix, eye, diags\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "import pylab\n",
    "from pylab import *\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "mpl.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "# ！\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "# 用来正常显示负号\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from sklearn import svm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def to_percent(temp, position):\n",
    "    return '%1.0f' % (100 * temp) + '%'\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#coding=utf-8\n",
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "from os.path import isdir\n",
    "import linecache\n",
    "# python自带的模块，缓存读取文件某一行的内容\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import copy as copy1\n",
    "import scipy\n",
    "import urllib\n",
    "# from scipy.signal import savgol_filter\n",
    "import urllib.parse\n",
    "from urllib.parse import urlparse\n",
    "import sys\n",
    "from numpy import loadtxt\n",
    "from numpy import savetxt\n",
    "from numpy.linalg import svd\n",
    "\n",
    "import pylab\n",
    "from pylab import *\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']\n",
    "#！\n",
    "mpl.rcParams['axes.unicode_minus']=False\n",
    "#用来正常显示负号\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks_cwt\n",
    "from scipy.sparse import linalg\n",
    "from scipy.sparse import csc_matrix, eye, diags\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy import cluster\n",
    "#用于进行层次聚类，话层次聚类图的工具包\n",
    "import sklearn\n",
    "from sklearn import decomposition as skldec\n",
    "#用于主成分分析降维的包\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "#tsne\n",
    "import joblib\n",
    "#保存、加载分类器模型\n",
    "#tree\n",
    "import sys\n",
    "#from sklearn.externals.six import StringIO\n",
    "from six import StringIO\n",
    "import pydotplus\n",
    "import graphviz\n",
    "from skimage import filters\n",
    "from sklearn import tree #树的模块\n",
    "#基于Otsu的阈值分割方法,无参数去背景\n",
    "#forest\n",
    "import math\n",
    "import warnings\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import sys\n",
    "#from sklearn.externals.six import StringIO\n",
    "import pydotplus\n",
    "from sklearn.metrics import classification_report\n",
    "#高斯朴素贝叶斯\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import  metrics\n",
    "\n",
    "#xgboost\n",
    "import xgboost\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "#LightGBM\n",
    "from sklearn.datasets import load_iris\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "#ROCq曲线AUC值\n",
    "# from sklearn import datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "# from sklearn.multiclass import OneVsRestClassifier\n",
    "# from scipy import interp\n",
    "#画图-混淆矩阵\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#-----------------------\n",
    "import struct\n",
    "# Kmeans模型\n",
    "import sklearn.cluster\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "#写入word\n",
    "import docx\n",
    "import docx.enum\n",
    "import docx.shared\n",
    "import docx.enum.text\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "import docx.oxml\n",
    "import docx.oxml.ns\n",
    "from docx.oxml.ns import qn\n",
    "from sklearn import tree               #导入模型\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "808b9593",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(r'./data/HHT数据/20230912改肠癌分期 - 副本.txt',sep='\\t',header=None)\n",
    "data_train = np.array(data_train)\n",
    "\n",
    "\n",
    "\n",
    "##光谱PCA=0.95\n",
    "data_train_pcaspec_x = data_train[:,1:15]\n",
    "data1_train_pcaspec_y = data_train[:,0]\n",
    "data_train_pcaspec, data_test_pcaspec, label_train_pcaspec, label_test_pcaspec = train_test_split(data_train_pcaspec_x,data1_train_pcaspec_y,shuffle=False,test_size=0.2)\n",
    "##光谱\n",
    "data_train_spec_x = data_train[:,15:1342]\n",
    "data1_train_spec_y = data_train[:,0]\n",
    "data_train_spec, data_test_spec, label_train_spec, label_test_spec = train_test_split(data_train_spec_x,data1_train_spec_y,shuffle=False,test_size=0.2)\n",
    "\n",
    "##HHT滤波的光谱PCA=0.95\n",
    "data_train_pcahht_x = data_train[:,1342:1370]\n",
    "data1_train_pcahht_y = data_train[:,0]\n",
    "data_train_pcahht, data_test_pcahht, label_train_pcahht, label_test_pcahht = train_test_split(data_train_pcahht_x,data1_train_pcahht_y,shuffle=False,test_size=0.2)\n",
    "##HHT滤波的光谱\n",
    "data_train_spechht_x = data_train[:,1370:2697]\n",
    "data1_train_spechht_y = data_train[:,0]\n",
    "data_train_spechht, data_test_spechht, label_train_spechht, label_test_spechht = train_test_split(data_train_spechht_x,data1_train_spechht_y,shuffle=False,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "172390ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(696, 14)\n",
      "(696, 1327)\n",
      "(696, 28)\n",
      "(696, 1327)\n",
      "(174, 14)\n",
      "(174, 1327)\n",
      "(174, 28)\n",
      "(174, 1327)\n"
     ]
    }
   ],
   "source": [
    "print(data_train_pcaspec.shape)\n",
    "print(data_train_spec.shape)\n",
    "print(data_train_pcahht.shape)\n",
    "print(data_train_spechht.shape)\n",
    "\n",
    "print(data_test_pcaspec.shape)\n",
    "print(data_test_spec.shape)\n",
    "print(data_test_pcahht.shape)\n",
    "print(data_test_spechht.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4bde996",
   "metadata": {},
   "outputs": [],
   "source": [
    "outPath =r'./result/HHT/0912'\n",
    "train_data=[]\n",
    "train_label=[]\n",
    "test_data=[]\n",
    "test_label=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18d25a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoreSVM：pcaspec \n",
      " 0.7285714285714285\n",
      "[0.7285714285714285]\n",
      "scoreSVM：pcaspec \n",
      " 0.6402877697841727\n",
      "[0.7285714285714285, 0.6402877697841727]\n",
      "scoreSVM：pcaspec \n",
      " 0.6762589928057554\n",
      "[0.7285714285714285, 0.6402877697841727, 0.6762589928057554]\n",
      "scoreSVM：pcaspec \n",
      " 0.6618705035971223\n",
      "[0.7285714285714285, 0.6402877697841727, 0.6762589928057554, 0.6618705035971223]\n",
      "scoreSVM：pcaspec \n",
      " 0.6402877697841727\n",
      "[0.7285714285714285, 0.6402877697841727, 0.6762589928057554, 0.6618705035971223, 0.6402877697841727]\n",
      "max： 0.7285714285714285\n",
      "索引： 0\n",
      "5次准确率： 0.6694552929085302\n",
      "scoreSVM： 0.6839080459770115\n",
      "\n",
      "\n",
      "scoreSVM：spec \n",
      " 0.7285714285714285\n",
      "[0.7285714285714285]\n",
      "scoreSVM：spec \n",
      " 0.8201438848920863\n",
      "[0.7285714285714285, 0.8201438848920863]\n",
      "scoreSVM：spec \n",
      " 0.7769784172661871\n",
      "[0.7285714285714285, 0.8201438848920863, 0.7769784172661871]\n",
      "scoreSVM：spec \n",
      " 0.762589928057554\n",
      "[0.7285714285714285, 0.8201438848920863, 0.7769784172661871, 0.762589928057554]\n",
      "scoreSVM：spec \n",
      " 0.7769784172661871\n",
      "[0.7285714285714285, 0.8201438848920863, 0.7769784172661871, 0.762589928057554, 0.7769784172661871]\n",
      "max： 0.8201438848920863\n",
      "索引： 1\n",
      "5次准确率： 0.7730524152106886\n",
      "scoreSVM： 0.8448275862068966\n",
      "\n",
      "\n",
      "scoreSVM：pcahht \n",
      " 0.7285714285714285\n",
      "[0.7285714285714285]\n",
      "scoreSVM：pcahht \n",
      " 0.6618705035971223\n",
      "[0.7285714285714285, 0.6618705035971223]\n",
      "scoreSVM：pcahht \n",
      " 0.697841726618705\n",
      "[0.7285714285714285, 0.6618705035971223, 0.697841726618705]\n",
      "scoreSVM：pcahht \n",
      " 0.6762589928057554\n",
      "[0.7285714285714285, 0.6618705035971223, 0.697841726618705, 0.6762589928057554]\n",
      "scoreSVM：pcahht \n",
      " 0.6690647482014388\n",
      "[0.7285714285714285, 0.6618705035971223, 0.697841726618705, 0.6762589928057554, 0.6690647482014388]\n",
      "max： 0.7285714285714285\n",
      "索引： 0\n",
      "5次准确率： 0.68672147995889\n",
      "scoreSVM： 0.6781609195402298\n",
      "\n",
      "\n",
      "scoreSVM：spechht \n",
      " 0.7285714285714285\n",
      "[0.7285714285714285]\n",
      "scoreSVM：spechht \n",
      " 0.7769784172661871\n",
      "[0.7285714285714285, 0.7769784172661871]\n",
      "scoreSVM：spechht \n",
      " 0.7338129496402878\n",
      "[0.7285714285714285, 0.7769784172661871, 0.7338129496402878]\n",
      "scoreSVM：spechht \n",
      " 0.7122302158273381\n",
      "[0.7285714285714285, 0.7769784172661871, 0.7338129496402878, 0.7122302158273381]\n",
      "scoreSVM：spechht \n",
      " 0.7553956834532374\n",
      "[0.7285714285714285, 0.7769784172661871, 0.7338129496402878, 0.7122302158273381, 0.7553956834532374]\n",
      "max： 0.7769784172661871\n",
      "索引： 1\n",
      "5次准确率： 0.7413977389516958\n",
      "scoreSVM： 0.8275862068965517\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_type_list = ['pcaspec','spec','pcahht','spechht']\n",
    "for dataset_type in dataset_type_list:\n",
    "    accu=0\n",
    "\n",
    "    num_k=0\n",
    "    l=[]\n",
    "    if dataset_type == \"pcaspec\":\n",
    "        train_data=data_train_pcaspec\n",
    "        train_label=label_train_pcaspec\n",
    "        test_data=data_test_pcaspec\n",
    "        test_label=label_test_pcaspec\n",
    "        \n",
    " \n",
    "    elif dataset_type == \"spec\":\n",
    "        train_data=data_train_spec\n",
    "        train_label=label_train_spec\n",
    "        test_data=data_test_spec\n",
    "        test_label=label_test_spec\n",
    " \n",
    "    elif dataset_type == \"pcahht\":\n",
    "        train_data=data_train_pcahht\n",
    "        train_label=label_train_pcahht\n",
    "        test_data=data_test_pcahht\n",
    "        test_label=label_test_pcahht\n",
    "\n",
    "    elif dataset_type == \"spechht\":\n",
    "        train_data=data_train_spechht\n",
    "        train_label=label_train_spechht\n",
    "        test_data=data_test_spechht\n",
    "        test_label=label_test_spechht\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    sfolder=StratifiedKFold(n_splits=5,shuffle=False)\n",
    "    for trainData_index,testData_index in sfolder.split(train_data,train_label):\n",
    "        num_k=num_k+1\n",
    "    #for trainData,testData in sfolder.split(XX,YY):\n",
    "        trainData_kfold=train_data[trainData_index]\n",
    "       \n",
    "        testData_kfold=train_data[testData_index]\n",
    "        #print('x',trainData.shape)\n",
    "        #print('y',YY[trainData.shape])\n",
    "        trainTarget_kfold=train_label[trainData_index]\n",
    "        testTarget_kfold=train_label[testData_index]\n",
    "        # *********************************************************************************************网格搜索和交叉验证\n",
    "        # modelSVM = svm.SVC(C=svmC,probability=True)\n",
    "        modelSVM = svm.SVC(decision_function_shape='ovr', probability=True, class_weight='balanced')\n",
    "        # class_weight = {1: 10},class_weight='balanced'\n",
    "        # kernel='linear'时，为线性核，C越大分类效果越好，但有可能会过拟合（defaul C=1）。\n",
    "        # kernel='rbf'时（default），为高斯核，gamma值越小，分类界面越连续；\n",
    "        # gamma值越大，分类界面越“散”，分类效果越好，但有可能会过拟合。\n",
    "        # kernel='rbf'时（default），为高斯核，\n",
    "        # 建立需要搜索的参数的范围\n",
    "        param_grid = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                      'C': [0.7, 0.8, 1]}\n",
    "        grid_search = GridSearchCV(modelSVM, param_grid, cv=3)\n",
    "        \n",
    "        try:\n",
    "            clf = grid_search.fit(trainData_kfold, trainTarget_kfold)\n",
    "        except:\n",
    "            clf = grid_search.fit(trainData_kfold, trainTarget_kfold)\n",
    "        # clf = grid_search.fit(trainData, trainTarget)\n",
    "        # 训练模\n",
    "        # *******************************************************************************************保存、加载分类器模型\n",
    "        # 保存模型\n",
    "        outPathSVM = outPath + '/' +'_svmModel_pca'+dataset_type+str(num_k)+'.pkl'\n",
    "        joblib.dump(clf, outPathSVM)\n",
    "        best_model_svm = grid_search.best_estimator_\n",
    "        y_scoreSVM1 = clf.predict(testData_kfold)\n",
    "        # 预测标签\n",
    "        y_scoreSVM = clf.predict_proba(testData_kfold)\n",
    "        # 预测概率，计算样本点到分割超平面的函数距离,各标签预测概率[0.8,0.2\n",
    "        scoreSVM = clf.score(testData_kfold, testTarget_kfold)\n",
    "        \n",
    "        accu=accu+scoreSVM\n",
    "        #accu_svm.append(scoreSVM)\n",
    "        print('scoreSVM：'+dataset_type,'\\n',scoreSVM)\n",
    "        #print('使用SVM预测数据的分类报告为：','\\n',classification_report(testTarget_kfold, clf.predict(testData_kfold)))\n",
    "        l.append(scoreSVM)\n",
    "        #print('使用SVM预测数据的分类报告为：','\\n',classification_report(testTarget_kfold, clf.predict(testData_kfold)))\n",
    "        print(l)\n",
    "        \n",
    "    \n",
    "    \n",
    "    max_l=max(l)\n",
    "    print('max：',max_l)\n",
    "    max_index_l=l.index(max(l))\n",
    "    print('索引：',max_index_l)\n",
    "    print('5次准确率：',accu/5)\n",
    "    clf2 = joblib.load( outPath + '/' + r'_svmModel_pca'+dataset_type+str(max_index_l+1)+'.pkl')\n",
    "    joblib.dump(clf2, outPathSVM)\n",
    "    best_model_svm = grid_search.best_estimator_\n",
    "    y_scoreSVM1 = clf2.predict(test_data)\n",
    "    # 预测标签\n",
    "    y_scoreSVM = clf2.predict_proba(test_data)\n",
    "    # 预测概率，计算样本点到分割超平面的函数距离,各标签预测概率[0.8,0.2\n",
    "    scoreSVM = clf2.score(test_data, test_label)\n",
    "    print('scoreSVM：',scoreSVM)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b78f820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoreknn：pcaspec \n",
      " 0.9071428571428571\n",
      "[0.9071428571428571]\n",
      "scoreknn：pcaspec \n",
      " 0.8633093525179856\n",
      "[0.9071428571428571, 0.8633093525179856]\n",
      "scoreknn：pcaspec \n",
      " 0.841726618705036\n",
      "[0.9071428571428571, 0.8633093525179856, 0.841726618705036]\n",
      "scoreknn：pcaspec \n",
      " 0.8920863309352518\n",
      "[0.9071428571428571, 0.8633093525179856, 0.841726618705036, 0.8920863309352518]\n",
      "scoreknn：pcaspec \n",
      " 0.920863309352518\n",
      "[0.9071428571428571, 0.8633093525179856, 0.841726618705036, 0.8920863309352518, 0.920863309352518]\n",
      "max： 0.920863309352518\n",
      "索引： 4\n",
      "5次准确率： 0.8850256937307297\n",
      "scoreknn： 0.9195402298850575\n",
      "\n",
      "\n",
      "scoreknn：spec \n",
      " 0.9142857142857143\n",
      "[0.9142857142857143]\n",
      "scoreknn：spec \n",
      " 0.8992805755395683\n",
      "[0.9142857142857143, 0.8992805755395683]\n",
      "scoreknn：spec \n",
      " 0.8920863309352518\n",
      "[0.9142857142857143, 0.8992805755395683, 0.8920863309352518]\n",
      "scoreknn：spec \n",
      " 0.9136690647482014\n",
      "[0.9142857142857143, 0.8992805755395683, 0.8920863309352518, 0.9136690647482014]\n",
      "scoreknn：spec \n",
      " 0.935251798561151\n",
      "[0.9142857142857143, 0.8992805755395683, 0.8920863309352518, 0.9136690647482014, 0.935251798561151]\n",
      "max： 0.935251798561151\n",
      "索引： 4\n",
      "5次准确率： 0.9109146968139774\n",
      "scoreknn： 0.9022988505747126\n",
      "\n",
      "\n",
      "scoreknn：pcahht \n",
      " 0.8571428571428571\n",
      "[0.8571428571428571]\n",
      "scoreknn：pcahht \n",
      " 0.8776978417266187\n",
      "[0.8571428571428571, 0.8776978417266187]\n",
      "scoreknn：pcahht \n",
      " 0.8776978417266187\n",
      "[0.8571428571428571, 0.8776978417266187, 0.8776978417266187]\n",
      "scoreknn：pcahht \n",
      " 0.8561151079136691\n",
      "[0.8571428571428571, 0.8776978417266187, 0.8776978417266187, 0.8561151079136691]\n",
      "scoreknn：pcahht \n",
      " 0.8776978417266187\n",
      "[0.8571428571428571, 0.8776978417266187, 0.8776978417266187, 0.8561151079136691, 0.8776978417266187]\n",
      "max： 0.8776978417266187\n",
      "索引： 1\n",
      "5次准确率： 0.8692702980472765\n",
      "scoreknn： 0.8563218390804598\n",
      "\n",
      "\n",
      "scoreknn：spechht \n",
      " 0.8428571428571429\n",
      "[0.8428571428571429]\n",
      "scoreknn：spechht \n",
      " 0.9064748201438849\n",
      "[0.8428571428571429, 0.9064748201438849]\n",
      "scoreknn：spechht \n",
      " 0.8920863309352518\n",
      "[0.8428571428571429, 0.9064748201438849, 0.8920863309352518]\n",
      "scoreknn：spechht \n",
      " 0.8776978417266187\n",
      "[0.8428571428571429, 0.9064748201438849, 0.8920863309352518, 0.8776978417266187]\n",
      "scoreknn：spechht \n",
      " 0.8705035971223022\n",
      "[0.8428571428571429, 0.9064748201438849, 0.8920863309352518, 0.8776978417266187, 0.8705035971223022]\n",
      "max： 0.9064748201438849\n",
      "索引： 1\n",
      "5次准确率： 0.8779239465570401\n",
      "scoreknn： 0.867816091954023\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_type_list = ['pcaspec','spec','pcahht','spechht']\n",
    "for dataset_type in dataset_type_list:\n",
    "    accu=0\n",
    "    num_k=0\n",
    "    l=[]\n",
    "    if dataset_type == \"pcaspec\":\n",
    "        train_data=data_train_pcaspec\n",
    "        train_label=label_train_pcaspec\n",
    "        test_data=data_test_pcaspec\n",
    "        test_label=label_test_pcaspec\n",
    "        \n",
    " \n",
    "    elif dataset_type == \"spec\":\n",
    "        train_data=data_train_spec\n",
    "        train_label=label_train_spec\n",
    "        test_data=data_test_spec\n",
    "        test_label=label_test_spec\n",
    " \n",
    "    elif dataset_type == \"pcahht\":\n",
    "        train_data=data_train_pcahht\n",
    "        train_label=label_train_pcahht\n",
    "        test_data=data_test_pcahht\n",
    "        test_label=label_test_pcahht\n",
    "\n",
    "    elif dataset_type == \"spechht\":\n",
    "        train_data=data_train_spechht\n",
    "        train_label=label_train_spechht\n",
    "        test_data=data_test_spechht\n",
    "        test_label=label_test_spechht\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    sfolder=StratifiedKFold(n_splits=5,shuffle=False)\n",
    "    for trainData_index,testData_index in sfolder.split(train_data,train_label):\n",
    "        num_k=num_k+1\n",
    "    #for trainData,testData in sfolder.split(XX,YY):\n",
    "        trainData_kfold=train_data[trainData_index]\n",
    "       \n",
    "        testData_kfold=train_data[testData_index]\n",
    "        #print('x',trainData.shape)\n",
    "        #print('y',YY[trainData.shape])\n",
    "        trainTarget_kfold=train_label[trainData_index]\n",
    "        testTarget_kfold=train_label[testData_index]\n",
    "        \n",
    "        knn = KNeighborsClassifier()\n",
    "        # 定义一个knn分类器对象\n",
    "        # int 型参数 knn算法中指定以最近的几个最近邻样本具有投票权，默认参数为5，n_neighbors=5\n",
    "        # str参数,即每个拥有投票权的样本是按什么比重投票，'uniform'表示等比重投票，\n",
    "        # 'distance'表示按距离反比投票，[callable]表示自己定义的一个函数\n",
    "        # str或者距离度量对象   即怎样度量距离,默认是闵氏距离\n",
    "        # 建立需要搜索的参数的范围\n",
    "        param_grid = {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance'], 'leaf_size': [20, 30, 40]}\n",
    "        grid_search_knn = GridSearchCV(knn, param_grid, cv=3)\n",
    "        try:\n",
    "            knn = grid_search_knn.fit(trainData_kfold, trainTarget_kfold)\n",
    "        except:\n",
    "            knn = grid_search_knn.fit(trainData_kfold, trainTarget_kfold)\n",
    "        # knn = grid_search_knn.fit(trainData, trainTarget)\n",
    "        # 训练模型\n",
    "        # *******************************************************************************************保存、加载分类器模型\n",
    "        # 保存模型\n",
    "        outPathKNN = outPath + '/' +'_knnModel_pca'+dataset_type+str(num_k)+'.pkl' \n",
    "        joblib.dump(knn, outPathKNN)\n",
    "        # 加载模型\n",
    "        #\n",
    "        best_model_knn = grid_search_knn.best_estimator_\n",
    "        \n",
    "        # knn.fit(trainData, trainTarget)\n",
    "        scoreKNN = knn.score(testData_kfold, testTarget_kfold)\n",
    "        # 测试数据准确率\n",
    "        \n",
    "        #print('scoreKNN：','\\n',scoreKNN)\n",
    "        y_scoreKNN1 = knn.predict(testData_kfold)\n",
    "        # 预测标签\n",
    "        y_scoreKNN = knn.predict_proba(testData_kfold)\n",
    "        # 预测标签概率\n",
    "         \n",
    "        accu=accu+scoreKNN\n",
    "        #accu_svm.append(scoreSVM)\n",
    "        print('scoreknn：'+dataset_type,'\\n',scoreKNN)\n",
    "        #print('使用KNN预测数据的分类报告为：','\\n',classification_report(testTarget_kfold, clf.predict(testData_kfold)))\n",
    "        l.append(scoreKNN)\n",
    "        #print('使用SVM预测数据的分类报告为：','\\n',classification_report(testTarget_kfold, clf.predict(testData_kfold)))\n",
    "        print(l)\n",
    "    max_l=max(l)\n",
    "    print('max：',max_l)\n",
    "    max_index_l=l.index(max(l))\n",
    "    print('索引：',max_index_l)\n",
    "    print('5次准确率：',accu/5)\n",
    "    clf2 = joblib.load( outPath + '/' + r'_knnModel_pca'+dataset_type+str(max_index_l+1)+'.pkl')\n",
    "    joblib.dump(clf2, outPathKNN)        \n",
    "\n",
    "    best_model_knn = grid_search.best_estimator_\n",
    "    y_scoreKNN1 = clf2.predict(test_data)\n",
    "    # 预测标签\n",
    "    y_scoreKNN = clf2.predict_proba(test_data)\n",
    "    # 预测概率，计算样本点到分割超平面的函数距离,各标签预测概率[0.8,0.2\n",
    "    scoreKNN = clf2.score(test_data, test_label)\n",
    "    print('scoreknn：',scoreKNN)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1174753d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoreLDA：pcaspec \n",
      " 0.6714285714285714\n",
      "[0.6714285714285714]\n",
      "scoreLDA：pcaspec \n",
      " 0.6402877697841727\n",
      "[0.6714285714285714, 0.6402877697841727]\n",
      "scoreLDA：pcaspec \n",
      " 0.6762589928057554\n",
      "[0.6714285714285714, 0.6402877697841727, 0.6762589928057554]\n",
      "scoreLDA：pcaspec \n",
      " 0.5755395683453237\n",
      "[0.6714285714285714, 0.6402877697841727, 0.6762589928057554, 0.5755395683453237]\n",
      "scoreLDA：pcaspec \n",
      " 0.5899280575539568\n",
      "[0.6714285714285714, 0.6402877697841727, 0.6762589928057554, 0.5755395683453237, 0.5899280575539568]\n",
      "max： 0.6762589928057554\n",
      "索引： 2\n",
      "5次准确率： 0.630688591983556\n",
      "scoreLDA： 0.6724137931034483\n",
      "\n",
      "\n",
      "scoreLDA：spec \n",
      " 0.7214285714285714\n",
      "[0.7214285714285714]\n",
      "scoreLDA：spec \n",
      " 0.7482014388489209\n",
      "[0.7214285714285714, 0.7482014388489209]\n",
      "scoreLDA：spec \n",
      " 0.6546762589928058\n",
      "[0.7214285714285714, 0.7482014388489209, 0.6546762589928058]\n",
      "scoreLDA：spec \n",
      " 0.6690647482014388\n",
      "[0.7214285714285714, 0.7482014388489209, 0.6546762589928058, 0.6690647482014388]\n",
      "scoreLDA：spec \n",
      " 0.6834532374100719\n",
      "[0.7214285714285714, 0.7482014388489209, 0.6546762589928058, 0.6690647482014388, 0.6834532374100719]\n",
      "max： 0.7482014388489209\n",
      "索引： 1\n",
      "5次准确率： 0.6953648509763617\n",
      "scoreLDA： 0.6839080459770115\n",
      "\n",
      "\n",
      "scoreLDA：pcahht \n",
      " 0.7\n",
      "[0.7]\n",
      "scoreLDA：pcahht \n",
      " 0.6834532374100719\n",
      "[0.7, 0.6834532374100719]\n",
      "scoreLDA：pcahht \n",
      " 0.697841726618705\n",
      "[0.7, 0.6834532374100719, 0.697841726618705]\n",
      "scoreLDA：pcahht \n",
      " 0.6330935251798561\n",
      "[0.7, 0.6834532374100719, 0.697841726618705, 0.6330935251798561]\n",
      "scoreLDA：pcahht \n",
      " 0.6762589928057554\n",
      "[0.7, 0.6834532374100719, 0.697841726618705, 0.6330935251798561, 0.6762589928057554]\n",
      "max： 0.7\n",
      "索引： 0\n",
      "5次准确率： 0.6781294964028778\n",
      "scoreLDA： 0.6954022988505747\n",
      "\n",
      "\n",
      "scoreLDA：spechht \n",
      " 0.5928571428571429\n",
      "[0.5928571428571429]\n",
      "scoreLDA：spechht \n",
      " 0.6474820143884892\n",
      "[0.5928571428571429, 0.6474820143884892]\n",
      "scoreLDA：spechht \n",
      " 0.6330935251798561\n",
      "[0.5928571428571429, 0.6474820143884892, 0.6330935251798561]\n",
      "scoreLDA：spechht \n",
      " 0.60431654676259\n",
      "[0.5928571428571429, 0.6474820143884892, 0.6330935251798561, 0.60431654676259]\n",
      "scoreLDA：spechht \n",
      " 0.48201438848920863\n",
      "[0.5928571428571429, 0.6474820143884892, 0.6330935251798561, 0.60431654676259, 0.48201438848920863]\n",
      "max： 0.6474820143884892\n",
      "索引： 1\n",
      "5次准确率： 0.5919527235354575\n",
      "scoreLDA： 0.6551724137931034\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_type_list = ['pcaspec','spec','pcahht','spechht']\n",
    "for dataset_type in dataset_type_list:\n",
    "    accu=0\n",
    "    num_k=0\n",
    "    l=[]\n",
    "    if dataset_type == \"pcaspec\":\n",
    "        train_data=data_train_pcaspec\n",
    "        train_label=label_train_pcaspec\n",
    "        test_data=data_test_pcaspec\n",
    "        test_label=label_test_pcaspec\n",
    "        \n",
    " \n",
    "    elif dataset_type == \"spec\":\n",
    "        train_data=data_train_spec\n",
    "        train_label=label_train_spec\n",
    "        test_data=data_test_spec\n",
    "        test_label=label_test_spec\n",
    " \n",
    "    elif dataset_type == \"pcahht\":\n",
    "        train_data=data_train_pcahht\n",
    "        train_label=label_train_pcahht\n",
    "        test_data=data_test_pcahht\n",
    "        test_label=label_test_pcahht\n",
    "\n",
    "    elif dataset_type == \"spechht\":\n",
    "        train_data=data_train_spechht\n",
    "        train_label=label_train_spechht\n",
    "        test_data=data_test_spechht\n",
    "        test_label=label_test_spechht\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "    sfolder=StratifiedKFold(n_splits=5,shuffle=False)\n",
    "    for trainData_index,testData_index in sfolder.split(train_data,train_label):\n",
    "        num_k=num_k+1\n",
    "    #for trainData,testData in sfolder.split(XX,YY):\n",
    "        trainData_kfold=train_data[trainData_index]\n",
    "       \n",
    "        testData_kfold=train_data[testData_index]\n",
    "        #print('x',trainData.shape)\n",
    "        #print('y',YY[trainData.shape])\n",
    "        trainTarget_kfold=train_label[trainData_index]\n",
    "        testTarget_kfold=train_label[testData_index]\n",
    "\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        # print('中心点',lda.means_)\n",
    "\n",
    "        # 建立需要搜索的参数的范围\n",
    "        param_grid = {'n_components': [1,2, 5, 10]}\n",
    "        grid_search_lda = GridSearchCV(lda, param_grid, cv=3)\n",
    "\n",
    "        try:\n",
    "            lda = grid_search_lda.fit(trainData_kfold, trainTarget_kfold)\n",
    "        except:\n",
    "            lda = grid_search_lda.fit(trainData_kfold, trainTarget_kfold)\n",
    "\n",
    "        # lda = grid_search_lda.fit(trainData, trainTarget)\n",
    "        # 训练模型\n",
    "        # *******************************************************************************************保存、加载分类器模型\n",
    "        # 保存模型\n",
    "        outPathLDA = outPath + '/' +'_ldaModel'+dataset_type+str(num_k)+'.pkl' \n",
    "        joblib.dump(lda, outPathLDA)\n",
    "        # 加载模型\n",
    "        #\n",
    "        best_model_lda = grid_search_lda.best_estimator_\n",
    "        # print(\"***\",type(grid_search.best_params_))\n",
    "        # print(type(grid_search.best_params_))\n",
    "        # print(\"默认超参数：\",best_model)\n",
    " \n",
    "        scoreLDA = lda.score(testData_kfold, testTarget_kfold)\n",
    "        # 测试数据准去率\n",
    "        # print('测试数据分类正确率', lda.score(X_test, Y_test))\n",
    "        y_scoreLDA1 = lda.predict(testData_kfold)\n",
    "        # 预测标签\n",
    "        y_scoreLDA = lda.predict_proba(testData_kfold)\n",
    "        # 预测标签概率\n",
    "        accu=accu+scoreLDA\n",
    "        #accu_svm.append(scoreSVM)\n",
    "        print('scoreLDA：'+dataset_type,'\\n',scoreLDA)\n",
    "        #print('使用KNN预测数据的分类报告为：','\\n',classification_report(testTarget_kfold, clf.predict(testData_kfold)))\n",
    "\n",
    "        l.append(scoreLDA)\n",
    "        #print('使用SVM预测数据的分类报告为：','\\n',classification_report(testTarget_kfold, clf.predict(testData_kfold)))\n",
    "        print(l)\n",
    "    max_l=max(l)\n",
    "    print('max：',max_l)\n",
    "    max_index_l=l.index(max(l))\n",
    "    print('索引：',max_index_l)\n",
    "    print('5次准确率：',accu/5)\n",
    "    clf2 = joblib.load( outPath + '/' + r'_ldaModel'+dataset_type+str(max_index_l+1)+'.pkl')\n",
    "    joblib.dump(clf2, outPathLDA)        \n",
    "\n",
    "    best_model_lda = grid_search_lda.best_estimator_\n",
    "\n",
    "\n",
    "    scoreLDA = clf2.score(test_data, test_label)\n",
    "\n",
    "    y_scoreLDA1 = clf2.predict(test_data)\n",
    "    # 预测标签\n",
    "    y_scoreLDA = clf2.predict_proba(test_data)\n",
    "    # 预测标签概率\n",
    "    accu=accu+scoreLDA\n",
    "    #accu_svm.append(scoreSVM)\n",
    "    print('scoreLDA：',scoreLDA)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d52d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a88e72f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
